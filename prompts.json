[
    "<| q tags=regex,html |>\nParsing HTML with regular expressions\nHow do I do this? Is it a good idea?\n<|/ q dscore=3 |>\n<| a dscore=4 |>",
    "<| file filename=string_utils.py |>\ndef count_words(string: str) -> Dict[str, int]:\n    \"\"\"Count the number of occurrences of each word in the string.\"\"\"",
    "<| q tags=python,pandas,dataframe |>\nIndexing pandas dataframe with array as iloc input - \"ValueError\"\nI have a pandas dataframe(df) which I want to index to only display columns where the total sum within the column is not zero. I am using the .to_numpy().nonzero() method to create a tuple of non-zero indexes. I checked the pandas.DataFrame.iloc documentation and found that only arrays / lists of int are available for indexing, so I change this tuple of non-zero indexes to a list:\n<code>\nimport pandas as pd",
    "<| file source=github ext=.py |>\nfrom setuptools import setup\nfrom setuptools_rust import Binding, RustExtension\n\nextras = {}\nextras[\"testing\"] = [\"pytest\", \"requests\", \"numpy\", \"datasets\"]\nextras[\"docs\"] = [\"sphinx\", \"sphinx_rtd_theme\", \"setuptools_rust\"]\n\nsetup(\n    name=\"tokenizers\",\n    version=\"0.11\",\n    description=\"Fast and Customizable Tokenizers\",\n    long_description=open(\"README.md\", \"r\", encoding=\"utf-8\").read(),\n    long_description_content_type=\"text/markdown\",\n    keywords=\"NLP tokenizer BPE transformer deep learning\",\n    author=\"Anthony MOI\",\n    author_email=\"anthony@huggingface.co\",\n    url=\"https://github.com/huggingface/tokenizers\",\n    license=\"Apache License 2.0\",\n    rust_extensions=[RustExtension(\"tokenizers.tokenizers\", binding=Binding.PyO3, debug=False)],\n    extras_require=extras,\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"Intended Audience :: Developers\",\n        \"Intended Audience :: Education\",\n        \"Intended Audience :: Science/Research\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Operating System :: OS Independent\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.5\",\n        \"Programming Language :: Python :: 3.6\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    ],\n    package_dir={\"\": \"py_src\"},\n    packages=[\n        \"tokenizers\",\n        \"tokenizers.models\",\n        \"tokenizers.decoders\",\n        \"tokenizers.normalizers\",\n        \"tokenizers.pre_tokenizers\",\n        \"tokenizers.processors\",\n        \"tokenizers.trainers\",\n        \"tokenizers.implementations\",\n        \"tokenizers.tools\",\n    ],\n    package_data={\n        \"tokenizers\": [\"py.typed\", \"__init__.pyi\"],\n        \"tokenizers.models\": [\"py.typed\", \"__init__.pyi\"],\n        \"tokenizers.decoders\": [\"py.typed\", \"__init__.pyi\"],\n        \"tokenizers.normalizers\": [\"py.typed\", \"__init__.pyi\"],\n        \"tokenizers.pre_tokenizers\": [\"py.typed\", \"__init__.pyi\"],\n        \"tokenizers.processors\": [\"py.typed\", \"__init__.pyi\"],\n        \"tokenizers.trainers\": [\"py.typed\", \"__init__.pyi\"],\n        \"tokenizers.implementations\": [\"py.typed\"],\n        \"tokenizers.tools\": [\"py.typed\", \"visualizer-styles.css\"],\n    },\n    zip_safe=False,\n)\n\n<|/ file filename=",
    "<| file filename=setup.py source=github dstars=2 |>\n",
    "<| file filename=visualize_features_pca.ipynb source=github |>\n",
    "<| file filename=traveling_salesman.cpp |>\n",
    "<| file filename=count_words.sh |>\n",
    "<| file filename=count_words.pl |>\n",
    "def fizzbuzz(limit):\n    \"\"\"Print the integers up to limit, but print 'fizz' for any multiples of 3 and 'buzz' for any multiples of 5\"\"\""
]
